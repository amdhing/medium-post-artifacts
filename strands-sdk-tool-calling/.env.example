# LLM Service Configuration
# Point to your FastAPI service from Article 1
OLLAMA_HOST=http://your-ec2-instance:8000
OLLAMA_MODEL=llama3.1:8b

# Model Parameters
MAX_TOKENS=4000
TEMPERATURE=0.7
TIMEOUT=720

# Application Configuration
LOG_LEVEL=INFO
