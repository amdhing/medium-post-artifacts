# Medium Post Artifacts

This repository contains supporting code and scripts for Medium articles about hosting LLMs and building AI applications.

## Articles

### 1. [Host Your Own Open-Source LLM on Amazon EC2](./hosting-llm-ec2/)
Complete guide to deploying Ollama and FastAPI on AWS infrastructure.

**What you'll learn:**
- EC2 instance selection and configuration
- Ollama installation and model management
- FastAPI service creation
- Production deployment considerations

### 2. [Building AI Applications with Strands SDK and Tool Calling](./strands-sdk-tool-calling/)
Build a complete AI application using the Strands SDK with tool calling capabilities.

**What you'll learn:**
- Strands SDK setup and configuration
- Creating AI agents with OllamaModel
- Implementing tool calling with calculator functionality
- Agent interaction patterns

## Quick Start

Each directory contains:
- Complete source code
- Installation scripts
- Configuration files
- Detailed README with step-by-step instructions

## Prerequisites

- AWS Account with EC2 access
- Basic Python knowledge
- Familiarity with REST APIs
- SSH access to Linux instances

## Support

For questions or issues:
- Check the individual README files in each project directory
- Review the corresponding Medium articles
- Open an issue in this repository

## License

MIT License - feel free to use these examples in your own projects.
